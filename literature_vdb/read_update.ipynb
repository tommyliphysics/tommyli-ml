{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a856e43-5c29-4200-91e0-7b976df0bcbb",
      "metadata": {
        "id": "9a856e43-5c29-4200-91e0-7b976df0bcbb"
      },
      "source": [
        "# A Vector Database of Classic English Literature\n",
        "\n",
        "In the [previous notebook](https://github.com/tommyliphysics/tommyli-ml/blob/main/literature_vdb/notebooks/create.ipynb) we created a vector database of English texts downloaded from [Project Gutenberg](https://www.gutenberg.org). We will now look at accessing this database to perform a vector search and add new texts. We will do this by creating a class called LiteratureSearch with the functions add() (for adding a book to the database) and search() (for querying the database)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lx4fQ4ZuUh7i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx4fQ4ZuUh7i",
        "outputId": "6665b607-8342-450e-842a-774a1cbbbff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark sentence_transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6wVC45GaXmds",
      "metadata": {
        "id": "6wVC45GaXmds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d81e43-bd40-4201-bccf-57aded8f73c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "import gc\n",
        "\n",
        "import urllib.request\n",
        "import regex\n",
        "\n",
        "def read_book(url):\n",
        "    try:\n",
        "        response = urllib.request.urlopen(url)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    else:\n",
        "        if response is None:\n",
        "            print(\"Error: no response.\")\n",
        "            return None, None\n",
        "\n",
        "        content = response.read().decode(\"utf-8\")\n",
        "        content = regex.sub(r'\\r\\n', '\\n', content)\n",
        "        if len(regex.findall(r'\\r', content)) > 0:\n",
        "            print(\"Warning: found stray carriage return.\")\n",
        "        book_title = regex.findall(\"Title: (.*?)[\\n]\", content)\n",
        "        author = regex.findall(\"Author: (.*?)[\\n]\", content)\n",
        "\n",
        "        if len(book_title) == 0:\n",
        "            print(\"Could not find name of book.\")\n",
        "            book_title = None\n",
        "        else:\n",
        "            book_title = book_title[0]\n",
        "            print(\"Book title: \", book_title)\n",
        "\n",
        "        if len(author) == 0:\n",
        "            print(\"Could not find name of author.\")\n",
        "            author = None\n",
        "        else:\n",
        "            author = author[0]\n",
        "            print(\"author: \", author)\n",
        "        if len(regex.findall(r'[\\*]+[\\s]+START OF THE PROJECT GUTENBERG EBOOK', content)) > 0:\n",
        "            content = regex.split(r'[\\*]+[\\s]+START OF THE PROJECT GUTENBERG EBOOK[^\\*]+[\\*]+', content)[1]\n",
        "            if len(regex.findall(r'[\\*]+[\\s]+END OF THE PROJECT GUTENBERG EBOOK', content)) > 0:\n",
        "                content = regex.split(r'[\\*]+[\\s]+END OF THE PROJECT GUTENBERG EBOOK[^\\*]+[\\*]+', content)[0]\n",
        "\n",
        "        blocks = regex.split(r'[\\n]{2,}', content)\n",
        "\n",
        "        samples = []\n",
        "        for block in blocks:\n",
        "            block = regex.sub(r'[\\n]+', ' ', block)\n",
        "            block = regex.sub(r'[\\s]+', ' ', block)\n",
        "            if len(block) > 0:\n",
        "                samples.append({'author': author, 'title': book_title, 'text': block})\n",
        "        response.close()\n",
        "\n",
        "        return samples, book_title, author\n",
        "\n",
        "class LiteratureSearch:\n",
        "    def __init__(self, books_fn, embeddings_fn, index_fn):\n",
        "      # load the Spark DataFrame\n",
        "        self.spark = SparkSession.builder.appName(\"Read\").getOrCreate()\n",
        "        self.df = self.spark.read.csv(books_fn, header=True, inferSchema=True)\n",
        "\n",
        "      # add time stamp for creation\n",
        "        if 'added_date' not in self.df.columns:\n",
        "            current_time = time.time()\n",
        "            self.df = self.df.withColumn('added_date', lit(current_time))\n",
        "\n",
        "        self.df.show()\n",
        "\n",
        "      # get list of authors and book titles\n",
        "        authors = self.df.select('author').distinct().collect()\n",
        "        self.author_list = []\n",
        "\n",
        "        for author in authors:\n",
        "            filtered = self.df.filter(self.df.author == author['author']).select('title').distinct().collect()\n",
        "            for row in filtered:\n",
        "                self.author_list.append({'author': author['author'], 'title': row['title']})\n",
        "\n",
        "        print(\"Found titles:\")\n",
        "        for row in self.author_list:\n",
        "            print(f\"{row['title']}\\tby {row['author']}\")\n",
        "        self.author_list = pd.DataFrame(self.author_list)\n",
        "\n",
        "      # load the sentence transformer model\n",
        "        self.sentence_transformer_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "      # load embeddings\n",
        "        self.embeddings = np.load(embeddings_fn)\n",
        "      # load search index\n",
        "        self.index_L2 = faiss.read_index(index_fn)\n",
        "\n",
        "        self.max_id = self.df.count()\n",
        "\n",
        "    def add(self, url):\n",
        "        new_samples, title, author = read_book(url)\n",
        "        if author in self.author_list['author'].unique():\n",
        "            if title in self.author_list[self.author_list['author']==author]['title'].unique():\n",
        "                print(f\"Error: {title} by {author} already exists in the collection.\")\n",
        "                return -1\n",
        "\n",
        "        current_time = time.time()\n",
        "        for sample in new_samples:\n",
        "            sample['id'] = self.max_id\n",
        "            self.max_id += 1\n",
        "            sample['added_date'] = current_time\n",
        "\n",
        "        new_samples_df = self.spark.createDataFrame(new_samples)\n",
        "        self.df = self.df.union(new_samples_df)\n",
        "        print(f\"Added {new_samples_df.count()} new samples to the pyspark dataframe.\")\n",
        "\n",
        "        new_texts = [sample['text'] for sample in new_samples]\n",
        "        new_embeddings = self.sentence_transformer_model.encode(new_texts)\n",
        "        self.embeddings = np.concatenate((self.embeddings, new_embeddings))\n",
        "        print(f\"Added new embeddings (new shape: {self.embeddings.shape}).\")\n",
        "        self.index_L2.add(new_embeddings)\n",
        "        print(f\"Added to index (new size: {self.index_L2.ntotal}).\")\n",
        "\n",
        "    def save(self, books_fn, embeddings_fn, index_fn):\n",
        "        self.df.repartition(1).write.mode('overwrite').csv(books_fn, header=True)\n",
        "        np.save('embeddings.npy', self.embeddings)\n",
        "        faiss.write_index(self.index_L2, \"index_L2.index\")\n",
        "\n",
        "    def search(self, query_text, k):\n",
        "        query_vector = self.sentence_transformer_model.encode(query_text)\n",
        "        distances, sorted_ids = self.index_L2.search(np.array([query_vector]), k)\n",
        "\n",
        "        sorted_ids = sorted_ids[0].tolist()\n",
        "        results = self.df.filter(self.df.id.isin(sorted_ids)).toPandas()\n",
        "        results['result'] = results['id'].apply(lambda x: sorted_ids.index(x)+1)\n",
        "        return results.sort_values(by='result').to_dict(orient='records')\n",
        "\n",
        "    def close(self):\n",
        "        del(self.index_L2)\n",
        "        del(self.embeddings)\n",
        "        self.spark.stop()\n",
        "        print(\"Stopped Spark session.\")\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdf427a-b38a-4e62-bb62-806439314d31",
      "metadata": {
        "id": "5fdf427a-b38a-4e62-bb62-806439314d31"
      },
      "source": [
        "Let's create an instance of LiteratureSearch, which will load the text as a Spark DataFrame, embeddings and search index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8da633ac-8499-4587-b6e0-e7c0647ad90d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8da633ac-8499-4587-b6e0-e7c0647ad90d",
        "outputId": "64d7ff84-2146-4768-894a-93ff026b4121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "|         author| id|                text|               title|         added_date|\n",
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "|Charles Dickens|  0|A TALE OF TWO CITIES|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  1|A STORY OF THE FR...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  2|  By Charles Dickens|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  3|            CONTENTS|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  4|Book the First--R...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  5|CHAPTER I The Per...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  6|Book the Second--...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  7|CHAPTER I Five Ye...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  8|Book the Third--t...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  9|CHAPTER I In Secr...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 10|Book the First--R...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 11|CHAPTER I. The Pe...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 12|It was the best o...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 13|There were a king...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 14|It was the year o...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 15|France, less favo...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 16|In England, there...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 17|All these things,...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 18|CHAPTER II. The Mail|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 19|It was the Dover ...|A Tale of Two Cities|1.724167494169181E9|\n",
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Found titles:\n",
            "A Christmas Carol\tby Charles Dickens\n",
            "David Copperfield\tby Charles Dickens\n",
            "A Tale of Two Cities\tby Charles Dickens\n",
            "Oliver Twist\tby Charles Dickens\n",
            "Great Expectations\tby Charles Dickens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "litsearch = LiteratureSearch('books.csv', 'embeddings.npy', 'index_L2.index')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add a few more books to the database:"
      ],
      "metadata": {
        "id": "7uvgiE0nWesA"
      },
      "id": "7uvgiE0nWesA"
    },
    {
      "cell_type": "code",
      "source": [
        "litsearch.add('https://www.gutenberg.org/cache/epub/730/pg730.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smKS3gsDnYrR",
        "outputId": "167116ac-e695-473e-81fe-c83f6b0c4c00"
      },
      "id": "smKS3gsDnYrR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book title:  Oliver Twist\n",
            "author:  Charles Dickens\n",
            "Error: Oliver Twist by Charles Dickens already exists in the collection.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "litsearch.add('https://www.gutenberg.org/cache/epub/766/pg766.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMhhNQBYnhbu",
        "outputId": "43c46e0f-62e5-47b7-f2e4-b71532ef673d"
      },
      "id": "IMhhNQBYnhbu",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book title:  David Copperfield\n",
            "author:  Charles Dickens\n",
            "Error: David Copperfield by Charles Dickens already exists in the collection.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now save the database to file."
      ],
      "metadata": {
        "id": "59hHoKeLW4x8"
      },
      "id": "59hHoKeLW4x8"
    },
    {
      "cell_type": "code",
      "source": [
        "litsearch.save('books.csv', 'embeddings.npy', 'index_L2.index')"
      ],
      "metadata": {
        "id": "Wpug0r9ITCSI"
      },
      "id": "Wpug0r9ITCSI",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "17eae2b6-e75a-4018-8a0d-65a6d1ad40b1",
      "metadata": {
        "id": "17eae2b6-e75a-4018-8a0d-65a6d1ad40b1"
      },
      "source": [
        "Let's now load a new instance of LiteratureSearch and see if our new books are in the database."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "litsearch.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXk-X4-akTPB",
        "outputId": "98da0d50-d0ad-4095-f1f6-86e378a69b4c"
      },
      "id": "cXk-X4-akTPB",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped Spark session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "skTLhur5dlbD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skTLhur5dlbD",
        "outputId": "f4075b86-5f55-43a3-d385-deabe02c81b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "|         author| id|                text|               title|         added_date|\n",
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "|Charles Dickens|  0|A TALE OF TWO CITIES|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  1|A STORY OF THE FR...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  2|  By Charles Dickens|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  3|            CONTENTS|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  4|Book the First--R...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  5|CHAPTER I The Per...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  6|Book the Second--...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  7|CHAPTER I Five Ye...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  8|Book the Third--t...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens|  9|CHAPTER I In Secr...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 10|Book the First--R...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 11|CHAPTER I. The Pe...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 12|It was the best o...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 13|There were a king...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 14|It was the year o...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 15|France, less favo...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 16|In England, there...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 17|All these things,...|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 18|CHAPTER II. The Mail|A Tale of Two Cities|1.724167494169181E9|\n",
            "|Charles Dickens| 19|It was the Dover ...|A Tale of Two Cities|1.724167494169181E9|\n",
            "+---------------+---+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Found titles:\n",
            "A Christmas Carol\tby Charles Dickens\n",
            "David Copperfield\tby Charles Dickens\n",
            "A Tale of Two Cities\tby Charles Dickens\n",
            "Oliver Twist\tby Charles Dickens\n",
            "Great Expectations\tby Charles Dickens\n"
          ]
        }
      ],
      "source": [
        "litsearch_new = LiteratureSearch('books.csv', 'embeddings.npy', 'index_L2.index')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we have successfully updated the database. Let's now perform a vector search."
      ],
      "metadata": {
        "id": "lCUzBWDLXQ3q"
      },
      "id": "lCUzBWDLXQ3q"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "jFjc69Yhhu_r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFjc69Yhhu_r",
        "outputId": "8be67a9c-d045-4094-c7ef-7e40e6c3cb4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'author': 'Charles Dickens',\n",
              "  'id': 12577,\n",
              "  'text': '‘Can you cook this young gentleman’s breakfast for him, if you please?’ said the Master at Salem House.',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 1},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 4338,\n",
              "  'text': 'Must they! Let them not hope to taste it!',\n",
              "  'title': 'Great Expectations',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 2},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 12526,\n",
              "  'text': '‘What have we got here?’ he said, putting a fork into my dish. ‘Not chops?’',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 3},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 15213,\n",
              "  'text': 'What with the novelty of this cookery, the excellence of it, the bustle of it, the frequent starting up to look after it, the frequent sitting down to dispose of it as the crisp slices came off the gridiron hot and hot, the being so busy, so flushed with the fire, so amused, and in the midst of such a tempting noise and savour, we reduced the leg of mutton to the bone. My own appetite came back miraculously. I am ashamed to record it, but I really believe I forgot Dora for a little while. I am satisfied that Mr. and Mrs. Micawber could not have enjoyed the feast more, if they had sold a bed to provide it. Traddles laughed as heartily, almost the whole time, as he ate and worked. Indeed we all did, all at once; and I dare say there was never a greater success.',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 4},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 15228,\n",
              "  'text': 'I thanked him and said, No; but would he take no dinner himself?',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 5},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 15730,\n",
              "  'text': 'I did not like to leave him, under such circumstances, and we all three dined together off a beefsteak pie--which was one of the many good things for which Peggotty was famous--and which was curiously flavoured on this occasion, I recollect well, by a miscellaneous taste of tea, coffee, butter, bacon, cheese, new loaves, firewood, candles, and walnut ketchup, continually ascending from the shop. After dinner we sat for an hour or so near the window, without talking much; and then Mr. Peggotty got up, and brought his oilskin bag and his stout stick, and laid them on the table.',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 6},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 10842,\n",
              "  'text': 'The soft-hearted cook added his intercession, and the result was that the man who had first appeared undertook its delivery.',\n",
              "  'title': 'Oliver Twist',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 7},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 14209,\n",
              "  'text': '‘Ain’t you?’ said the waiter. ‘Young gentlemen is generally tired of beef and mutton: have a weal cutlet!’',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 8},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 19023,\n",
              "  'text': '‘Let him come in here!’ said I.',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 9},\n",
              " {'author': 'Charles Dickens',\n",
              "  'id': 12529,\n",
              "  'text': 'So he took a chop by the bone in one hand, and a potato in the other, and ate away with a very good appetite, to my extreme satisfaction. He afterwards took another chop, and another potato; and after that, another chop and another potato. When we had done, he brought me a pudding, and having set it before me, seemed to ruminate, and to become absent in his mind for some moments.',\n",
              "  'title': 'David Copperfield',\n",
              "  'added_date': 1724167494.169181,\n",
              "  'result': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "litsearch_new.search(\"Let him cook!\", 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we are done with the database, we need to close it.  "
      ],
      "metadata": {
        "id": "oflZCg3drnN0"
      },
      "id": "oflZCg3drnN0"
    },
    {
      "cell_type": "code",
      "source": [
        "litsearch_new.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGWTM6oqrmSQ",
        "outputId": "9987ab36-1764-4c34-d3b0-e781f070b483"
      },
      "id": "WGWTM6oqrmSQ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped Spark session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this series of notebooks we've seen how to create a vector database using a combination of PySpark, a sentence transformer and FAISS. Another option is to use existing vector search capabilities in cloud database services, e.g. AWS OpenSearch or MongoDB Atlas. The procedure there is similar to the one described here, but with a few differences: rather than storing the text and embeddings in separate files, one can store the embeddings as well as the text as attributes within the same collection. A search index can then be created using cloud services, and a vector search can be performed via an API."
      ],
      "metadata": {
        "id": "Y3-csEfIYsN9"
      },
      "id": "Y3-csEfIYsN9"
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}